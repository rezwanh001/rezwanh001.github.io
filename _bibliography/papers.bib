---
---

% This file is part of the Rezwan's paper lists.

@inproceedings{haque2025signer,
  abbr={ICCV 2025},
  bibtex_show={true},
  title={A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition},
  author={Haque, Md Rezwanul and Islam, Md Milon and Raju, SM and Karray, Fakhri},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4931--4940},
  year={2025},
  abstract={Continuous Sign Language Recognition (CSLR) faces multiple challenges, including significant inter-signer variability and poor generalization to novel sentence structures. Traditional solutions frequently fail to handle these issues efficiently. For overcoming these constraints, we propose a dual-architecture framework. For the Signer-Independent (SI) challenge, we propose a Signer-Invariant Conformer that combines convolutions with multi-head self-attention to learn robust, signer-agnostic representations from pose-based skeletal keypoints. For the Unseen-Sentences (US) task, we designed a Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that captures both fine-grained posture dynamics, enabling the model’s ability to comprehend novel grammatical compositions. Experiments on the challenging Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US task, the transformer model scores a WER of 47.78%, surpassing previous work. In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th in the SI task, demonstrating the performance of these models. The findings validate our key hypothesis: that developing task-specific networks designed for the particular challenges of CSLR leads to considerable performance improvements and establishes a new baseline for further research. The source code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.},
  html={https://openaccess.thecvf.com/content/ICCV2025W/MSLR/html/Haque_A_Signer-Invariant_Conformer_and_Multi-Scale_Fusion_Transformer_for_Continuous_Sign_ICCVW_2025_paper.html},
  pdf={https://openaccess.thecvf.com/content/ICCV2025W/MSLR/papers/Haque_A_Signer-Invariant_Conformer_and_Multi-Scale_Fusion_Transformer_for_Continuous_Sign_ICCVW_2025_paper.pdf},
  preview={signer.png},
  selected={true},
}

@inproceedings{islam2025fusionensemble,
  abbr={ICCV 2025},
  bibtex_show={true},
  title={FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition},
  author={Islam, Md Milon and Haque, Md Rezwanul and Raju, SM and Karray, Fakhri},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4924--4930},
  year={2025},
  abstract={Accurate recognition of sign language in healthcare communication poses a significant challenge, requiring frameworks that can accurately interpret complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net, a novel attention-based ensemble of spatiotemporal networks that dynamically fuses visual and motion data to enhance recognition accuracy. The proposed approach processes RGB video and range Doppler map radar modalities synchronously through four different spatiotemporal networks. For each network, features from both modalities are continuously fused using an attention-based fusion module before being fed into an ensemble of classifiers. Finally, the outputs of these four different fused channels are combined in an ensemble classification head, thereby enhancing the model’s robustness. Experiments demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for Italian Sign Language. Our findings indicate that an ensemble of diverse spatiotemporal networks, unified by attention-based fusion, yields a robust and accurate framework for complex, multimodal isolated gesture recognition tasks. The source code is available at: https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.},
  html={https://openaccess.thecvf.com/content/ICCV2025W/MSLR/html/Islam_FusionEnsemble-Net_An_Attention-Based_Ensemble_of_Spatiotemporal_Networks_for_Multimodal_Sign_ICCVW_2025_paper.html},
  pdf={https://openaccess.thecvf.com/content/ICCV2025W/MSLR/papers/Islam_FusionEnsemble-Net_An_Attention-Based_Ensemble_of_Spatiotemporal_Networks_for_Multimodal_Sign_ICCVW_2025_paper.pdf},
  preview={fusionensemble.png},
  selected={true},
}

@article{haque2025mdd,
  abbr={IEEE SMC 2025},
  bibtex_show={true},
  title={MDD-Net: Multimodal Depression Detection through Mutual Transformer},
  author={Haque, Md Rezwanul and Islam, Md Milon and Raju, SM and Altaheri, Hamdi and Nassar, Lobna and Karray, Fakhri},
  journal={arXiv preprint arXiv:2508.08093},
  year={2025},
  abstract={Depression is a major mental health condition that severely impacts the emotional and physical well-being of individuals. The simple nature of data collection from social media platforms has attracted significant interest in properly utilizing this information for mental health research. A Multimodal Depression Detection Network (MDD-Net), utilizing acoustic and visual data obtained from social media networks, is proposed in this work where mutual transformers are exploited to efficiently extract and fuse multimodal features for efficient depression detection. The MDD-Net consists of four core modules: an acoustic feature extraction module for retrieving relevant acoustic attributes, a visual feature extraction module for extracting significant high-level patterns, a mutual transformer for computing the correlations among the generated features and fusing these features from multiple modalities, and a detection layer for detecting depression using the fused feature representations. The extensive experiments are performed using the multimodal D-Vlog dataset, and the findings reveal that the developed multimodal depression detection network surpasses the state-of-the-art by up to 17.37% for F1-Score, demonstrating the greater performance of the proposed system. The source code is accessible at https://github.com/rezwanh001/Multimodal-Depression-Detection.},
  html={https://arxiv.org/html/2508.08093v1},
  pdf={https://arxiv.org/pdf/2508.08093},
  preview={mdd.png},
  selected={true},
}

@article{haque2025mmfformer,
  abbr={IEEE SMC 2025},
  bibtex_show={true},
  title={MMFformer: Multimodal Fusion Transformer Network for Depression Detection},
  author={Haque, Md Rezwanul and Islam, Md Milon and Raju, SM and Altaheri, Hamdi and Nassar, Lobna and Karray, Fakhri},
  journal={arXiv preprint arXiv:2508.06701},
  year={2025},
  abstract={Depression is a serious mental health illness that significantly affects an individual’s well-being and quality of life, making early detection crucial for adequate care and treatment. Detecting depression is often difficult, as it is based primarily on subjective evaluations during clinical interviews. Hence, the early diagnosis of depression, thanks to the content of social networks, has become a prominent research area. The extensive and diverse nature of user-generated information poses a significant challenge, limiting the accurate extraction of relevant temporal information and the effective fusion of data across multiple modalities. This paper introduces MMFformer, a multimodal depression detection network designed to retrieve depressive spatio-temporal high-level patterns from multimodal social media information. The transformer network with residual connections captures spatial features from videos, and a transformer encoder is exploited to design important temporal dynamics in audio. Moreover, the fusion architecture fused the extracted features through late and intermediate fusion strategies to find out the most relevant intermodal correlations among them. Finally, the proposed network is assessed on two large-scale depression detection datasets, and the results clearly reveal that it surpasses existing state-of-the-art approaches, improving the F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is made available publicly at https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.},
  html={https://arxiv.org/html/2508.06701v1},
  pdf={https://arxiv.org/pdf/2508.06701},
  preview={mmfformer.png},
  selected={true},
}

@article{raju2025gnn,
  abbr={IJCNN 2025},
  bibtex_show={true},
  title={GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning},
  author={Raju, SM and Islam, Md Milon and Haque, Md Rezwanul and Altaheri, Hamdi and Karray, Fakhri},
  journal={arXiv preprint arXiv:2507.07006},
  year={2025},
  abstract={Microscopic assessment of histopathology images is vital for accurate cancer diagnosis and treatment. Whole Slide Image (WSI) classification and captioning have become crucial tasks in computer-aided pathology. However, microscopic WSI face challenges such as redundant patches and unknown patch positions due to subjective pathologist captures. Moreover, generating automatic pathology captions remains a significant challenge. To address these issues, we introduce a novel GNN-ViTCap framework for classification and caption generation from histopathological microscopic images. First, a visual feature extractor generates patch embeddings. Redundant patches are then removed by dynamically clustering these embeddings using deep embedded clustering and selecting representative patches via a scalar dot attention mechanism. We build a graph by connecting each node to its nearest neighbors in the similarity matrix and apply a graph neural network to capture both local and global context. The aggregated image embeddings are projected into the language model's input space through a linear layer and combined with caption tokens to fine-tune a large language model. We validate our method on the BreakHis and PatchGastric datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569 for captioning. Experimental results demonstrate that GNN-ViTCap outperforms state of the art approaches, offering a reliable and efficient solution for microscopy based patient diagnosis.},
  html={https://arxiv.org/abs/2507.07006},
  pdf={https://arxiv.org/pdf/2507.07006},
  preview={GNN-ViTCap.png}
}

@inproceedings{haque2023body,
  abbr={ICCIT 2023},
  bibtex_show={true},
  title={Body Weight Estimation Using Smartphone Based Photoplethysmography Signal},
  author={Haque, Md Rezwanul and Ritom, MHC and Noman, AA and Haque, E and Ahmed, F and others},
  booktitle={2023 26th International Conference on Computer and Information Technology (ICCIT)},
  pages={1--6},
  year={2023},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/10441018},
  preview={haque2023body.gif}
}

@inproceedings{haque2023smartphone,
  abbr={ATC 2023},
  bibtex_show={true},
  title={Smartphone Based BP Level Monitoring System Using DNN Model},
  author={Haque, Md Rezwanul and Al Noman, Abdullah and Haque, Emranul and Ahmed, Feroz and others},
  booktitle={2023 International Conference on Advanced Technologies for Communications (ATC)},
  pages={12--18},
  year={2023},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/10318933},
  preview={haque2023smartphone.gif}
}

@inproceedings{shihab2023badlad,
  abbr={ICDAR 2023},
  bibtex_show={true},
  title={Badlad: A large multi-domain bengali document layout analysis dataset},
  author={Shihab, Md Istiak Hossain and Hasan, Md Rakibul and Emon, Mahfuzur Rahman and Hossen, Syed Mobassir and Ansary, Md Nazmuddoha and Ahmed, Intesur and Rakib, Fazle Rabbi and Dhruvo, Shahriar Elahi and Dip, Souhardya Saha and Pavel, Akib Hasan and Meghla, Marsia Haque and Haque, Md Rezwanul and others},
  booktitle={International Conference on Document Analysis and Recognition},
  pages={326--341},
  year={2023},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-031-41676-7_19},
  preview={badlad.png}
}

@article{haque2021corrections,
  abbr={IEEE Access},
  bibtex_show={true},
  title={Corrections to" A Novel Technique for Non-Invasive Measurement of Human Blood Component Levels From Fingertip Video Using DNN Based Models".},
  author={Haque, Md Rezwanul and Raju, SM Taslim Uddin and Golap, MD Asaf-Uddowla and Hashem, MMA},
  journal={IEEE Access},
  volume={9},
  pages={84178--84179},
  year={2021},
  pdf={https://www.researchgate.net/profile/Mma-Hashem/publication/352990952_Corrections_to_''A_Novel_Technique_for_Non-Invasive_Measurement_of_Human_Blood_Component_Levels_From_Fingertip_Video_Using_DNN_Based_Models''/links/60e27bfc299bf1ea9ee1134a/Corrections-to-A-Novel-Technique-for-Non-Invasive-Measurement-of-Human-Blood-Component-Levels-From-Fingertip-Video-Using-DNN-Based-Models.pdf},
  preview={haque2021corrections.png}
}

@article{akter2021prediction,
  abbr={Springer},
  bibtex_show={true},
  title={Prediction of cervical cancer from behavior risk using machine learning techniques},
  author={Akter, Laboni and Islam, Md Milon and Al-Rakhami, Mabrook S and Haque, Md Rezwanul},
  journal={SN Computer Science},
  volume={2},
  number={3},
  pages={177},
  year={2021},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-021-00551-6},
  preview={akter2021prediction.png},
}

@article{golap2021hemoglobin,
  abbr={Elsevier},
  bibtex_show={true},
  title={Hemoglobin and glucose level estimation from PPG characteristics features of fingertip video using MGGP-based model},
  author={Golap, Md Asaf-uddowla and Raju, SM Taslim Uddin and Haque, Md Rezwanul and Hashem, MMA},
  journal={Biomedical Signal Processing and Control},
  volume={67},
  pages={102478},
  year={2021},
  publisher={Elsevier},
  html={https://www.sciencedirect.com/science/article/pii/S1746809421000756},
  pdf={golap2021hemoglobin.pdf},
  preview={golap2021hemoglobin.jpg}
}

@article{ullah2021scalable,
  abbr={Springer},
  bibtex_show={true},
  title={Scalable telehealth services to combat novel coronavirus (COVID-19) pandemic},
  author={Ullah, Shah Muhammad Azmat and Islam, Md Milon and Mahmud, Saifuddin and Nooruddin, Sheikh and Raju, SM Taslim Uddin and Haque, Md Rezwanul},
  journal={SN Computer Science},
  volume={2},
  pages={1--8},
  year={2021},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-020-00401-x},
  preview={ullah2021scalable.png}
}

@article{haque2021novel,
  abbr={IEEE Access},
  bibtex_show={true},
  title={A novel technique for non-invasive measurement of human blood component levels from fingertip video using DNN based models},
  author={Haque, Md Rezwanul and Raju, SM Taslim Uddin and Golap, Md Asaf-Uddowla and Hashem, MMA},
  journal={IEEE Access},
  volume={9},
  pages={19025--19042},
  year={2021},
  publisher={IEEE},
  abstract={Blood components such as hemoglobin, glucose, and creatinine are essential for monitoring one's health condition. The current blood component measurement approaches still depend on invasive techniques that are painful and uncomfortable for patients. To facilitate measurement at home, we proposed a novel non-invasive technique to measure blood hemoglobin, glucose, and creatinine levels based on Photoplethysmography (PPG) signals using Deep Neural Networks (DNN). Fingertip videos from 93 subjects have been collected using a smartphone. The PPG signal is generated from each video, and 46 characteristic features are then extracted from the PPG signal, its derivatives (1st and 2nd), and from Fourier analysis. Additionally, age and gender are also included as features due to their significant effects on hemoglobin, glucose, and creatinine. A correlation-based feature selection (CFS) using genetic algorithms (GA) has been used to select the optimal features to avoid redundancy and overfitting. Finally, DNN-based models have been developed to estimate the blood Hemoglobin (Hb), Glucose (Gl), and Creatinine (Cr) levels from the selected features. The approach provides the best-estimated accuracy of R² = 0.922 for Hb, R² = 0.902 for Gl, and R² = 0.969 for Cr. Experimental results show that the proposed method is a suitable technique to be used clinically to measure human blood component levels without taking blood samples. This paper also reveals that smartphone-based PPG signals have great potential to measure different blood components.},
  html={https://ieeexplore.ieee.org/document/9335002},
  pdf={A_Novel_Technique_for_Non-Invasive_Measurement_of_Human_Blood_Component_Levels_From_Fingertip_Video_Using_DNN_Based_Models.pdf},
  preview={IEEE-access-haque2021novel.jpg},
  selected={true},
}

@article{asraf2020deep,
  abbr={Springer},
  bibtex_show={true},
  title={Deep learning applications to combat novel coronavirus (COVID-19) pandemic},
  author={Asraf, Amanullah and Islam, Md Zabirul and Haque, Md Rezwanul and Islam, Md Milon},
  journal={SN Computer Science},
  volume={1},
  pages={1--7},
  year={2020},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-020-00383-w},
  preview={asraf2020deep.png},
}

@article{islam2020breast,
  abbr={Springer},
  bibtex_show={true},
  title={Breast cancer prediction: a comparative study using machine learning techniques},
  author={Islam, Md Milon and Haque, Md Rezwanul and Iqbal, Hasib and Hasan, Md Munirul and Hasan, Mahmudul and Kabir, Muhammad Nomani},
  journal={SN Computer Science},
  volume={1},
  pages={1--14},
  year={2020},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-020-00305-w},
  preview={islam2020breast.png}
}

@article{haque2019computer,
  abbr={MECS Press},
  bibtex_show={true},
  title={A computer vision based lane detection approach},
  author={Haque, Md Rezwanul and Islam, Md Milon and Alam, Kazi Saeed and Iqbal, Hasib and Shaik, Md Ebrahim},
  journal={International Journal of Image, Graphics and Signal Processing},
  volume={10},
  number={3},
  pages={27},
  year={2019},
  publisher={Modern Education and Computer Science Press},
  pdf={https://www.mecs-press.org/ijigsp/ijigsp-v11-n3/IJIGSP-V11-N3-4.pdf},
  preview={haque2019computer.png}
}

@inproceedings{haque2018performance,
  abbr={IC4ME2 2018},
  bibtex_show={true},
  title={Performance evaluation of random forests and artificial neural networks for the classification of liver disorder},
  author={Haque, Md Rezwanul and Islam, Md Milon and Iqbal, Hasib and Reza, Md Sumon and Hasan, Md Kamrul},
  booktitle={2018 international conference on computer, communication, chemical, material and electronic engineering (IC4ME2)},
  pages={1--5},
  year={2018},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/8465658},
  preview={haque2018performance.png}
}

@inproceedings{islam2017prediction,
  abbr={R10-HTC 2017},
  bibtex_show={true},
  title={Prediction of breast cancer using support vector machine and K-Nearest neighbors},
  author={Islam, Md Milon and Iqbal, Hasib and Haque, Md Rezwanul and Hasan, Md Kamrul},
  booktitle={2017 IEEE region 10 humanitarian technology conference (R10-HTC)},
  pages={226--229},
  year={2017},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/8288944},
  preview={islam2017prediction.png}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

inproceedings{haque2025signer,
    abbr={ICCV 2025 Workshop},
    bibtex_show={true},
    title={A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition},
    author={Haque, Md Rezwanul and Islam, Md. Milon and Raju, S M Taslim Uddin and Karray, Fakhri},
    journal={Accepted at Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025},
    year={2025}
}

inproceedings{islam2025fusionensemble,
    abbr={ICCV 2025 Workshop},
    bibtex_show={true},
    title={FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition},
    author={Islam, Md. Milon and Haque, Md Rezwanul and Raju, S M Taslim Uddin and Karray, Fakhri},
    journal={Accepted at Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025},
    year={2025}
}

inproceedings{haque2025mmfformer,
  abbr={IEEE SMC 2025},
  bibtex_show={true},
  title={MMFformer: Multimodal Fusion Transformer Network for Depression Detection},
  author={Haque, Md Rezwanul and Islam, Md. Milon and Raju, S M Taslim Uddin and Altaheri, Hamdi and Nassar, Lobna and Karray, Fakhri},
  journal={Accepted at Proceedings of the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vienna, Austria},
  year={2025}
}

inproceedings{haque2025mdd,
    abbr={IEEE SMC 2025},
    bibtex_show={true},
    title={MDD-Net: Multimodal Depression Detection through Mutual Transformer},
    author={Haque, Md Rezwanul and Islam, Md. Milon and Raju, S M Taslim Uddin and Altaheri, Hamdi and Nassar, Lobna and Karray, Fakhri},
    journal={Accepted at Proceedings of the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vienna, Austria},
    year={2025}
}

article{raju2025gnn,
  abbr={IJCNN 2025},
  bibtex_show={true},
  title={GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning},
  author={Raju, SM and Islam, Md Milon and Haque, Md Rezwanul and Altaheri, Hamdi and Karray, Fakhri},
  journal={arXiv preprint arXiv:2507.07006},
  year={2025},
  % google_scholar_id={qxL8FJ1GzNcC},
  abstract={Microscopic assessment of histopathology images is vital for accurate cancer diagnosis and treatment. Whole Slide Image (WSI) classification and captioning have become crucial tasks in computer-aided pathology. However, microscopic WSI face challenges such as redundant patches and unknown patch positions due to subjective pathologist captures. Moreover, generating automatic pathology captions remains a significant challenge. To address these issues, we introduce a novel GNN-ViTCap framework for classification and caption generation from histopathological microscopic images. First, a visual feature extractor generates patch embeddings. Redundant patches are then removed by dynamically clustering these embeddings using deep embedded clustering and selecting representative patches via a scalar dot attention mechanism. We build a graph by connecting each node to its nearest neighbors in the similarity matrix and apply a graph neural network to capture both local and global context. The aggregated image embeddings are projected into the language model's input space through a linear layer and combined with caption tokens to fine-tune a large language model. We validate our method on the BreakHis and PatchGastric datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569 for captioning. Experimental results demonstrate that GNN-ViTCap outperforms state of the art approaches, offering a reliable and efficient solution for microscopy based patient diagnosis.},
  html={https://arxiv.org/abs/2507.07006},
  pdf={https://arxiv.org/pdf/2507.07006},
  preview={GNN-ViTCap.png},
  selected={true},
}

inproceedings{haque2023body,
  abbr={ICCIT 2023},
  bibtex_show={true},
  title={Body Weight Estimation Using Smartphone Based Photoplethysmography Signal},
  author={Haque, Md Rezwanul and Ritom, MHC and Noman, AA and Haque, E and Ahmed, F and others},
  booktitle={2023 26th International Conference on Computer and Information Technology (ICCIT)},
  pages={1--6},
  year={2023},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/10441018},
  % google_scholar_id={M3ejUd6NZC8C},
  preview={haque2023body.gif}
}

inproceedings{haque2023smartphone,
  abbr={ATC 2023},
  bibtex_show={true},
  title={Smartphone Based BP Level Monitoring System Using DNN Model},
  author={Haque, Md Rezwanul and Al Noman, Abdullah and Haque, Emranul and Ahmed, Feroz and others},
  booktitle={2023 International Conference on Advanced Technologies for Communications (ATC)},
  pages={12--18},
  year={2023},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/10318933},
  % google_scholar_id={4TOpqqG69KYC},
  preview={haque2023smartphone.gif}
}

inproceedings{shihab2023badlad,
  abbr={ICDAR 2023},
  bibtex_show={true},
  title={Badlad: A large multi-domain bengali document layout analysis dataset},
  author={Shihab, Md Istiak Hossain and Hasan, Md Rakibul and Emon, Mahfuzur Rahman and Hossen, Syed Mobassir and Ansary, Md Nazmuddoha and Ahmed, Intesur and Rakib, Fazle Rabbi and Dhruvo, Shahriar Elahi and Dip, Souhardya Saha and Pavel, Akib Hasan and Meghla, Marsia Haque and Haque, Md Rezwanul and others},
  booktitle={International Conference on Document Analysis and Recognition},
  pages={326--341},
  year={2023},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-031-41676-7_19},
  % google_scholar_id={_kc_bZDykSQC},
  preview={badlad.png}
}

article{haque2021corrections,
  abbr={IEEE Access},
  bibtex_show={true},
  title={Corrections to" A Novel Technique for Non-Invasive Measurement of Human Blood Component Levels From Fingertip Video Using DNN Based Models".},
  author={Haque, Md Rezwanul and Raju, SM Taslim Uddin and Golap, MD Asaf-Uddowla and Hashem, MMA},
  journal={IEEE Access},
  volume={9},
  pages={84178--84179},
  year={2021},
  pdf={https://www.researchgate.net/profile/Mma-Hashem/publication/352990952_Corrections_to_''A_Novel_Technique_for_Non-Invasive_Measurement_of_Human_Blood_Component_Levels_From_Fingertip_Video_Using_DNN_Based_Models''/links/60e27bfc299bf1ea9ee1134a/Corrections-to-A-Novel-Technique-for-Non-Invasive-Measurement-of-Human-Blood-Component-Levels-From-Fingertip-Video-Using-DNN-Based-Models.pdf},
  % google_scholar_id={YOwf2qJgpHMC},
  preview={haque2021corrections.png}
}

article{akter2021prediction,
  abbr={Springer},
  bibtex_show={true},
  title={Prediction of cervical cancer from behavior risk using machine learning techniques},
  author={Akter, Laboni and Islam, Md Milon and Al-Rakhami, Mabrook S and Haque, Md Rezwanul},
  journal={SN Computer Science},
  volume={2},
  number={3},
  pages={177},
  year={2021},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-021-00551-6},
  % google_scholar_id={roLk4NBRz8UC},
  preview={akter2021prediction.png},
}

article{golap2021hemoglobin,
  abbr={Elsevier},
  bibtex_show={true},
  title={Hemoglobin and glucose level estimation from PPG characteristics features of fingertip video using MGGP-based model},
  author={Golap, Md Asaf-uddowla and Raju, SM Taslim Uddin and Haque, Md Rezwanul and Hashem, MMA},
  journal={Biomedical Signal Processing and Control},
  volume={67},
  pages={102478},
  year={2021},
  publisher={Elsevier},
  % google_scholar_id={LkGwnXOMwfcC},
  html={https://www.sciencedirect.com/science/article/pii/S1746809421000756},
  pdf={golap2021hemoglobin.pdf},
  preview={golap2021hemoglobin.jpg}
}

article{ullah2021scalable,
  abbr={Springer},
  bibtex_show={true},
  title={Scalable telehealth services to combat novel coronavirus (COVID-19) pandemic},
  author={Ullah, Shah Muhammad Azmat and Islam, Md Milon and Mahmud, Saifuddin and Nooruddin, Sheikh and Raju, SM Taslim Uddin and Haque, Md Rezwanul},
  journal={SN Computer Science},
  volume={2},
  pages={1--8},
  year={2021},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-020-00401-x},
  % google_scholar_id={ufrVoPGSRksC},
  preview={ullah2021scalable.png}
}

article{haque2021novel,
  abbr={IEEE Access},
  bibtex_show={true},
  title={A novel technique for non-invasive measurement of human blood component levels from fingertip video using DNN based models},
  author={Haque, Md Rezwanul and Raju, SM Taslim Uddin and Golap, Md Asaf-Uddowla and Hashem, MMA},
  journal={IEEE Access},
  volume={9},
  pages={19025--19042},
  year={2021},
  publisher={IEEE},
  abstract={Blood components such as hemoglobin, glucose, and creatinine are essential for monitoring one's health condition. The current blood component measurement approaches still depend on invasive techniques that are painful and uncomfortable for patients. To facilitate measurement at home, we proposed a novel non-invasive technique to measure blood hemoglobin, glucose, and creatinine levels based on Photoplethysmography (PPG) signals using Deep Neural Networks (DNN). Fingertip videos from 93 subjects have been collected using a smartphone. The PPG signal is generated from each video, and 46 characteristic features are then extracted from the PPG signal, its derivatives (1st and 2nd), and from Fourier analysis. Additionally, age and gender are also included as features due to their significant effects on hemoglobin, glucose, and creatinine. A correlation-based feature selection (CFS) using genetic algorithms (GA) has been used to select the optimal features to avoid redundancy and overfitting. Finally, DNN-based models have been developed to estimate the blood Hemoglobin (Hb), Glucose (Gl), and Creatinine (Cr) levels from the selected features. The approach provides the best-estimated accuracy of R² = 0.922 for Hb, R² = 0.902 for Gl, and R² = 0.969 for Cr. Experimental results show that the proposed method is a suitable technique to be used clinically to measure human blood component levels without taking blood samples. This paper also reveals that smartphone-based PPG signals have great potential to measure different blood components.},
  html={https://ieeexplore.ieee.org/document/9335002},
  pdf={A_Novel_Technique_for_Non-Invasive_Measurement_of_Human_Blood_Component_Levels_From_Fingertip_Video_Using_DNN_Based_Models.pdf},
  % google_scholar_id={_FxGoFyzp5QC},
  preview={IEEE-access-haque2021novel.jpg},
  selected={true},
}

article{asraf2020deep,
  abbr={Springer},
  bibtex_show={true},
  title={Deep learning applications to combat novel coronavirus (COVID-19) pandemic},
  author={Asraf, Amanullah and Islam, Md Zabirul and Haque, Md Rezwanul and Islam, Md Milon},
  journal={SN Computer Science},
  volume={1},
  pages={1--7},
  year={2020},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-020-00383-w},
  % google_scholar_id={IjCSPb-OGe4C},
  preview={asraf2020deep.png},
}

article{islam2020breast,
  abbr={Springer},
  bibtex_show={true},
  title={Breast cancer prediction: a comparative study using machine learning techniques},
  author={Islam, Md Milon and Haque, Md Rezwanul and Iqbal, Hasib and Hasan, Md Munirul and Hasan, Mahmudul and Kabir, Muhammad Nomani},
  journal={SN Computer Science},
  volume={1},
  pages={1--14},
  year={2020},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s42979-020-00305-w},
  % google_scholar_id={2osOgNQ5qMEC},
  preview={islam2020breast.png}
}

article{haque2019computer,
  abbr={MECS Press},
  bibtex_show={true},
  title={A computer vision based lane detection approach},
  author={Haque, Md Rezwanul and Islam, Md Milon and Alam, Kazi Saeed and Iqbal, Hasib and Shaik, Md Ebrahim},
  journal={International Journal of Image, Graphics and Signal Processing},
  volume={10},
  number={3},
  pages={27},
  year={2019},
  publisher={Modern Education and Computer Science Press},
  pdf={https://www.mecs-press.org/ijigsp/ijigsp-v11-n3/IJIGSP-V11-N3-4.pdf},
  % google_scholar_id={u5HHmVD_uO8C},
  preview={haque2019computer.png}
}

inproceedings{haque2018performance,
  abbr={IC4ME2 2018},
  bibtex_show={true},
  title={Performance evaluation of random forests and artificial neural networks for the classification of liver disorder},
  author={Haque, Md Rezwanul and Islam, Md Milon and Iqbal, Hasib and Reza, Md Sumon and Hasan, Md Kamrul},
  booktitle={2018 international conference on computer, communication, chemical, material and electronic engineering (IC4ME2)},
  pages={1--5},
  year={2018},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/8465658},
  % google_scholar_id={u-x6o8ySG0sC},
  preview={haque2018performance.png}
}

inproceedings{islam2017prediction,
  abbr={R10-HTC 2017},
  bibtex_show={true},
  title={Prediction of breast cancer using support vector machine and K-Nearest neighbors},
  author={Islam, Md Milon and Iqbal, Hasib and Haque, Md Rezwanul and Hasan, Md Kamrul},
  booktitle={2017 IEEE region 10 humanitarian technology conference (R10-HTC)},
  pages={226--229},
  year={2017},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/8288944},
  % google_scholar_id={d1gkVwhDpl0C},
  preview={islam2017prediction.png}
}

%%%%%%%%%%% %%%%%%%%%%% %%%%%%%%%%%

book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true},
  inspirehep_id = {3255}
}

article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}
